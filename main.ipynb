{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "oFASMUILsB5L",
      "metadata": {
        "id": "oFASMUILsB5L"
      },
      "source": [
        "## Master's Project: Application of Deep Learning for Solar Panel Detection in Satellite Imagery"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b78ecaa",
      "metadata": {},
      "source": [
        "One of the current global trends is the transition towards renewable energy sources, which helps to mitigate the effects of climate change, reduces environmental pollution and opens new prospects for energy policy reforms. Solar photovoltaic (PV) installations have become key contributors to renewable energy development, driven by the decreasing cost of producing PV cells and the increasing electrification of the energy system.\n",
        "\n",
        "The scale of PV deployment ranges from residential rooftop installations to large industrial solar farms. Tracking the geographic locations of existing PV plants is essential for infrastructure development, statistical insights and project planning. However, in many countries, the available data is highly decentralized due to the wide scale of PV\n",
        "utilization and the diversity of forms of solar plants. Not all of actual power generation from solar is accurately recorded in governmental, local or commercial databases. The lack of reliable information poses significant challenges for many participants in the energy market, primarily for network operators, project developers, policymakers and cell manufacturers. Therefore, an accurate and comprehensive database of solar panel locations and generation capacities would provide better understanding of demographic, geographic and regional trends."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "767d0196",
      "metadata": {},
      "source": [
        "**Project aim:** evaluate different deep learning network configurations in detecting solar panel installations in satellite imagery and estimate their generation capacity\n",
        "\n",
        "**Project objectives:**\n",
        "\n",
        "- Collect satellite imagery data and solar panel annotations\n",
        "- Generate binary masks highlighting solar panels \n",
        "- Filter, split and augment the data \n",
        "- Train fully convolutional network architectures (U-Net, FPN and PSPNet) with different encoder backbones (EfficientNet-B5, ResNet-50, MiT-B3)\n",
        "- Evaluate the models' performance \n",
        "- Estimate the solar energy generation capacity of the identified PV panels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8ab0203",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the project folder path\n",
        "folder_path = f\"G:/Meine Ablage/MS Thesis/solar_panel_segmentation\" # specify your own"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d184b8d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "pip install -r requirements.txt --index-url https://download.pytorch.org/whl/cu1211"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i7yqbculzD48",
      "metadata": {
        "id": "i7yqbculzD48"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KcdrPGfGzi9H",
      "metadata": {
        "id": "KcdrPGfGzi9H"
      },
      "outputs": [],
      "source": [
        "# Standard library\n",
        "import gc\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from glob import glob\n",
        "from io import BytesIO\n",
        "\n",
        "# Data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# GIS & Remote Sensing\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "from rasterio.features import rasterize\n",
        "from shapely.geometry import box\n",
        "from owslib.wms import WebMapService\n",
        "\n",
        "# Image processing\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "# Machine Learning & Deep Learning\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Metrics & Evaluation\n",
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    accuracy_score,\n",
        "    jaccard_score,\n",
        "    f1_score\n",
        ")\n",
        "\n",
        "# Utilities\n",
        "from tqdm import tqdm\n",
        "from natsort import natsorted\n",
        "import requests\n",
        "\n",
        "# Energy modeling\n",
        "import PySAM.Pvwattsv8 as pvwatts\n",
        "import pvlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qUbxh-S1zJnE",
      "metadata": {
        "id": "qUbxh-S1zJnE"
      },
      "source": [
        "### Data input"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf81b08b",
      "metadata": {},
      "source": [
        "- [German state boundaries](https://gdz.bkg.bund.de/index.php/default/verwaltungsgebiete-1-250-000-stand-01-01-vg250-01-01.html)\n",
        "- [Solar panel polygons](https://www.mdpi.com/2306-5729/7/9/128#B8-data-07-00128)\n",
        "- [WMS satellite imagery](https://isk.geobasis-bb.de/mapproxy/dop20c/service/wms)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb525e10",
      "metadata": {},
      "source": [
        "All the input data, trained models, JSON files with losses and evaluation metrics can be found in [**Google Drive**](https://drive.google.com/drive/folders/10p3SCaN2at0BQcw9AK6mUX1jUAQTx9J_?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30a1b3fc",
      "metadata": {
        "id": "30a1b3fc"
      },
      "outputs": [],
      "source": [
        "# Data of state boundaties in Germany\n",
        "# https://gdz.bkg.bund.de/index.php/default/verwaltungsgebiete-1-250-000-stand-01-01-vg250-01-01.html\n",
        "\n",
        "states = gpd.read_file(f\"{folder_path}/VG250_LAN.shp\")\n",
        "\n",
        "# Filter Brandenburg\n",
        "bb = states[states['GEN'] == 'Brandenburg']\n",
        "bb = bb.to_crs(\"EPSG:3857\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2122f971",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2122f971",
        "outputId": "59b7c80c-0b60-477b-c6da-798859a6d78c"
      },
      "outputs": [],
      "source": [
        "# Solar panels in Brandenburg\n",
        "\n",
        "# Metadata: https://www.mdpi.com/2306-5729/7/9/128#B8-data-07-00128\n",
        "# Download: https://zenodo.org/records/8188601\n",
        "\n",
        "solar = gpd.read_file(f\"{folder_path}/Solarenergy_Polygons_V20230420.geojson\")\n",
        "solar = solar.to_crs(\"EPSG:3857\")\n",
        "\n",
        "# Select only panels within Brandenburg\n",
        "bb_solar = solar[solar.intersects(bb.unary_union)].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "790b7bac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "790b7bac",
        "outputId": "938537b5-976e-4b58-a15a-48cfeb368759"
      },
      "outputs": [],
      "source": [
        "# Save file\n",
        "bb_solar.to_file(os.path.join(folder_path, f\"solar_brandenburg.gpkg\"), driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72e457bd",
      "metadata": {
        "id": "72e457bd"
      },
      "outputs": [],
      "source": [
        "# Create tile geometries\n",
        "# Get bounds of study area\n",
        "xmin, ymin, xmax, ymax = bb.total_bounds\n",
        "\n",
        "# Generate tiles\n",
        "tile_size = 512 # in meters\n",
        "tiles = []\n",
        "for x in range(int(xmin), int(xmax), tile_size):\n",
        "    for y in range(int(ymin), int(ymax), tile_size):\n",
        "        tile_geom = box(x, y, x + tile_size, y + tile_size)\n",
        "        tiles.append(tile_geom)\n",
        "\n",
        "tiles_gdf = gpd.GeoDataFrame(geometry=tiles, crs=\"EPSG:3857\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "432e50a4",
      "metadata": {
        "id": "432e50a4"
      },
      "outputs": [],
      "source": [
        "# Keep tiles that intersect with Brandenburg's bounds\n",
        "tiles_gdf = tiles_gdf[tiles_gdf.intersects(bb.unary_union)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c465fb9d",
      "metadata": {
        "id": "c465fb9d"
      },
      "outputs": [],
      "source": [
        "# Saving the tiles\n",
        "tiles_gdf = tiles_gdf.reset_index(drop=True)\n",
        "tiles_gdf.to_file(os.path.join(folder_path, f\"tiles_brandenburg.gpkg\"), driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8ca5c2d",
      "metadata": {
        "id": "b8ca5c2d"
      },
      "outputs": [],
      "source": [
        "# Read the file\n",
        "tiles_gdf = gpd.read_file(f\"{folder_path}/tiles_brandenburg.gpkg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fabf5e96",
      "metadata": {
        "id": "fabf5e96"
      },
      "outputs": [],
      "source": [
        "# Download satellite image tiles\n",
        "\n",
        "# Extract tiles from WMS\n",
        "wms_url = \"https://isk.geobasis-bb.de/mapproxy/dop20c/service/wms\"\n",
        "layer_name = \"bebb_dop20c\"\n",
        "tile_size = 512 # meters\n",
        "output_dir = os.path.join(folder_path, \"images\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Connect to the WMS\n",
        "wms = WebMapService(wms_url, version=\"1.3.0\")\n",
        "\n",
        "# Request and save WMS images for matched tiles\n",
        "for idx, row in tiles_gdf[:].iterrows():\n",
        "    minx, miny, maxx, maxy = row.geometry.bounds\n",
        "\n",
        "    bbox = f\"{minx},{miny},{maxx},{maxy}\"\n",
        "\n",
        "    params = {\n",
        "        \"SERVICE\": \"WMS\",\n",
        "        \"VERSION\": \"1.3.0\",\n",
        "        \"REQUEST\": \"GetMap\",\n",
        "        \"LAYERS\": layer_name,\n",
        "        \"STYLES\": \"\",\n",
        "        \"CRS\": \"EPSG:3857\",\n",
        "        \"BBOX\": bbox,\n",
        "        \"WIDTH\": tile_size,\n",
        "        \"HEIGHT\": tile_size,\n",
        "        \"FORMAT\": \"image/jpeg\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(wms_url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        image = Image.open(BytesIO(response.content))\n",
        "        image.save(os.path.join(output_dir, f\"tile_{idx}.png\"))\n",
        "    print(f\"Saved tile_{idx}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95077873",
      "metadata": {},
      "source": [
        "### Mask generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8875caa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "a8875caa",
        "outputId": "9211ab31-3389-46fe-804e-db6926fd3dd7"
      },
      "outputs": [],
      "source": [
        "# Create a mask for each tile\n",
        "output_dir = f\"{folder_path}/masks\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for idx, row in tqdm(tiles_gdf.iterrows(), total=len(tiles_gdf)):\n",
        "    bounds = row.geometry.bounds\n",
        "    tile_geom = box(*bounds)\n",
        "\n",
        "    transform = rasterio.transform.from_bounds(*bounds, 512, 512)\n",
        "    panels_in_tile = bb_solar[bb_solar.intersects(tile_geom)]\n",
        "\n",
        "    mask = rasterize(\n",
        "        [(geom, 1) for geom in panels_in_tile.geometry],\n",
        "        out_shape=(512, 512),\n",
        "        transform=transform,\n",
        "        fill=0,\n",
        "        dtype=np.uint8\n",
        "    )\n",
        "\n",
        "    # Save mask as PNG\n",
        "    mask_path = os.path.join(output_dir, f\"mask_{idx}.png\")\n",
        "    Image.fromarray(mask * 255).save(mask_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85d974d0",
      "metadata": {},
      "source": [
        "### Data filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3ac5b19",
      "metadata": {
        "id": "e3ac5b19",
        "outputId": "fe42fd14-c61a-4ea6-fd9b-1358a29048ac"
      },
      "outputs": [],
      "source": [
        "# Filter all masks that contain panels plus an equal number of those without panels\n",
        "\n",
        "mask_dir = f\"{folder_path}/masks\"\n",
        "image_dir = f\"{folder_path}/images\"\n",
        "\n",
        "output_mask_dir = os.path.join(folder_path, \"filtered_masks\")\n",
        "output_image_dir = os.path.join(folder_path, \"filtered_images\")\n",
        "os.makedirs(output_mask_dir, exist_ok=True)\n",
        "os.makedirs(output_image_dir, exist_ok=True)\n",
        "\n",
        "# Separate lists for masks with and without panels\n",
        "has_panel = []\n",
        "no_panel = []\n",
        "\n",
        "# Categorize masks\n",
        "for filename in os.listdir(mask_dir):\n",
        "    if filename.endswith(\".png\"):\n",
        "        mask_path = os.path.join(mask_dir, filename)\n",
        "        mask = np.array(Image.open(mask_path))\n",
        "\n",
        "        if mask.max() > 0:\n",
        "            has_panel.append(filename)\n",
        "        else:\n",
        "            no_panel.append(filename)\n",
        "\n",
        "# Sample equal number of no-panel images\n",
        "random.seed(42)\n",
        "no_panel_sample = random.sample(no_panel, len(has_panel))\n",
        "\n",
        "# Combine and copy selected masks/images\n",
        "selected_files = has_panel + no_panel_sample\n",
        "\n",
        "for fname in selected_files:\n",
        "    shutil.copy(os.path.join(mask_dir, fname), os.path.join(output_mask_dir, fname))\n",
        "    shutil.copy(os.path.join(image_dir, fname.replace(\"mask_\", \"tile_\")), os.path.join(output_image_dir, fname.replace(\"mask_\", \"tile_\")))\n",
        "\n",
        "print(f\"Copied {len(has_panel)} masks with panels and {len(no_panel_sample)} without panels.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05a3e90f",
      "metadata": {},
      "source": [
        "### Data split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c340fd",
      "metadata": {
        "id": "b4c340fd"
      },
      "outputs": [],
      "source": [
        "# Define paths to the images and masks\n",
        "image_paths = natsorted(glob(f\"{folder_path}/filtered_images/*.png\"))\n",
        "mask_paths = natsorted(glob(f\"{folder_path}/filtered_masks/*.png\"))\n",
        "\n",
        "# Keep only base names\n",
        "image_paths = [os.path.basename(p) for p in image_paths]\n",
        "mask_paths = [os.path.basename(p) for p in mask_paths]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e061214a",
      "metadata": {
        "id": "e061214a"
      },
      "outputs": [],
      "source": [
        "# Split the data into train / val / test sets\n",
        "'''\n",
        "Train: 70% — used to train the model\n",
        "\n",
        "Validation: 15% — used to tune hyperparameters and monitor overfitting\n",
        "\n",
        "Test: 15% — used to evaluate final model performance\n",
        "'''\n",
        "\n",
        "# Split into train+val and test\n",
        "img_trainval, img_test, mask_trainval, mask_test = train_test_split(\n",
        "    image_paths, mask_paths, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# Split train+val into train and val\n",
        "img_train, img_val, mask_train, mask_val = train_test_split(\n",
        "    img_trainval, mask_trainval, test_size=0.176, random_state=42  # 0.176 ≈ 15% / 85%\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l2whnW0hAmz_",
      "metadata": {
        "id": "l2whnW0hAmz_"
      },
      "outputs": [],
      "source": [
        "# Create folders for training, validation and test sets\n",
        "base_dir = f\"{folder_path}/solar_detection/datasets\"\n",
        "splits = ['train', 'val', 'test']\n",
        "for split in splits:\n",
        "    os.makedirs(os.path.join(base_dir, split, \"images\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(base_dir, split, \"masks\"), exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mFzgn7GNB_sm",
      "metadata": {
        "id": "mFzgn7GNB_sm"
      },
      "outputs": [],
      "source": [
        "# Copy files for each split\n",
        "base_dir = f\"{folder_path}/solar_detection/datasets\"\n",
        "image_dir = f\"{folder_path}/solar_detection/filtered_images\"\n",
        "mask_dir = f\"{folder_path}/solar_detection/filtered_masks\"\n",
        "\n",
        "def copy_split(images, masks, split):\n",
        "    for img, msk in zip(images, masks):\n",
        "        shutil.copy(os.path.join(image_dir, img), os.path.join(base_dir, split, \"images\", img))\n",
        "        shutil.copy(os.path.join(mask_dir, msk), os.path.join(base_dir, split, \"masks\", msk))\n",
        "\n",
        "copy_split(img_train, mask_train, \"train\")\n",
        "copy_split(img_val, mask_val, \"val\")\n",
        "copy_split(img_test, mask_test, \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qLi3CYdychO4",
      "metadata": {
        "id": "qLi3CYdychO4"
      },
      "outputs": [],
      "source": [
        "# Read the folders\n",
        "base_dir = f\"{folder_path}/solar_detection/datasets\"\n",
        "img_train  = natsorted(glob(f\"{base_dir}/train/images/*.png\"))\n",
        "mask_train = natsorted(glob(f\"{base_dir}/train/masks/*.png\"))\n",
        "\n",
        "img_val  = natsorted(glob(f\"{base_dir}/val/images/*.png\"))\n",
        "mask_val = natsorted(glob(f\"{base_dir}/val/masks/*.png\"))\n",
        "\n",
        "img_test  = natsorted(glob(f\"{base_dir}/test/images/*.png\"))\n",
        "mask_test = natsorted(glob(f\"{base_dir}/test/masks/*.png\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ce2e974",
      "metadata": {},
      "source": [
        "### Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7242b17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data augmentation: horizontal flipping, image rotation, shift-scaling transformations and normalization\n",
        "\n",
        "train_transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.3), \n",
        "    A.RandomRotate90(p=0.3),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=20, p=0.3),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # ImageNet stats\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "test_transform = A.Compose([\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83671cc9",
      "metadata": {},
      "source": [
        "### Network configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f728d39c",
      "metadata": {
        "id": "f728d39c"
      },
      "outputs": [],
      "source": [
        "# Dataset class\n",
        "class SolarPanelDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.array(Image.open(self.image_paths[idx]).convert(\"RGB\").resize((512, 512)))\n",
        "        mask = np.array(Image.open(self.mask_paths[idx]).convert(\"L\").resize((512, 512)))\n",
        "        mask = (mask > 0.5).astype(np.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented[\"image\"]\n",
        "            mask = augmented[\"mask\"].unsqueeze(0)\n",
        "        else:\n",
        "            image = torch.tensor(image / 255.0, dtype=torch.float).permute(2, 0, 1)\n",
        "            mask = torch.tensor(mask, dtype=torch.float).unsqueeze(0)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64ec2e19",
      "metadata": {
        "id": "64ec2e19"
      },
      "outputs": [],
      "source": [
        "# Create Dataset objects and DataLoaders\n",
        "train_dataset = SolarPanelDataset(img_train, mask_train, transform=train_transform)\n",
        "val_dataset = SolarPanelDataset(img_val, mask_val, transform=val_transform)\n",
        "test_dataset = SolarPanelDataset(img_test, mask_test, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b3b8b1",
      "metadata": {
        "id": "d6b3b8b1"
      },
      "outputs": [],
      "source": [
        "# Define model architectures with different backbones\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# Model architectures\n",
        "architectures = {\n",
        "    \"unet\": smp.Unet, # U-Net\n",
        "    \"fpn\": smp.FPN, # Feature Pyramid Network\n",
        "    \"pspnet\": smp.PSPNet # Pyramid Scene Parsing Network\n",
        "}\n",
        "\n",
        "# Encoder backbones\n",
        "backbones = ['mit_b3', 'resnet50', 'efficientnet-b5'] # MiT-B3, ResNet-50, EfficientNet-B5\n",
        "\n",
        "models = {}\n",
        "optimizers = {}\n",
        "\n",
        "for arch_name, arch_class in architectures.items():\n",
        "    for encoder in backbones:\n",
        "        model_name = f\"{arch_name}_{encoder}\"\n",
        "        model = arch_class(\n",
        "            encoder_name=encoder,\n",
        "            encoder_weights=\"imagenet\",\n",
        "            in_channels=3,\n",
        "            classes=1,\n",
        "            activation=None\n",
        "        ).to(device)\n",
        "        models[model_name] = model\n",
        "        optimizers[model_name] = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdxih3-ez2n6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdxih3-ez2n6",
        "outputId": "782e74df-ea59-43ab-af8e-65be8f742844"
      },
      "outputs": [],
      "source": [
        "# Calculate a balanced weight for the positive class in Binary Cross Entropy Loss\n",
        "mask_paths = natsorted(glob(f\"{folder_path}/solar_detection/filtered_masks/*.png\"))\n",
        "\n",
        "total_pos = 0\n",
        "total_neg = 0\n",
        "\n",
        "for path in tqdm(mask_paths):\n",
        "    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = (mask > 127).astype(np.uint8)\n",
        "\n",
        "    pos = np.sum(mask == 1)\n",
        "    neg = np.sum(mask == 0)\n",
        "\n",
        "    total_pos += pos\n",
        "    total_neg += neg\n",
        "\n",
        "pos_weight = total_neg / total_pos\n",
        "print(\"Calculated pos_weight:\", pos_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c95ec37",
      "metadata": {
        "id": "1c95ec37"
      },
      "outputs": [],
      "source": [
        "# Define loss functions: Dice loss and Binary Cross Entropy loss\n",
        "dice_loss_fn = smp.losses.DiceLoss(mode='binary')\n",
        "\n",
        "# Define BCE loss with positive class weight\n",
        "pos_weight = torch.tensor([pos_weight]).to(device)\n",
        "bce_loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_HYN16y0gVFT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HYN16y0gVFT",
        "outputId": "0eac7ca2-bc2b-4426-e434-a3af741b6e3a"
      },
      "outputs": [],
      "source": [
        "# Model training and validating\n",
        "num_epochs = 5\n",
        "history = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    optimizer = optimizers[model_name]\n",
        "    print(f\"Training model: {model_name}\")\n",
        "\n",
        "    history[model_name] = {\n",
        "        \"train_loss\": [],\n",
        "        \"val_loss\": []\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        running_train_loss = 0.0\n",
        "\n",
        "        train_bar = tqdm(train_loader, desc=f\"{model_name} - Training\", leave=False)\n",
        "        for images, masks in train_bar:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "\n",
        "            dice_loss = dice_loss_fn(torch.sigmoid(outputs), masks)\n",
        "            bce_loss = bce_loss_fn(outputs, masks)\n",
        "            loss = dice_loss + bce_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_train_loss += loss.item()\n",
        "            train_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_train_loss = running_train_loss / len(train_loader)\n",
        "        history[model_name][\"train_loss\"].append(avg_train_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "\n",
        "        val_bar = tqdm(val_loader, desc=f\"{model_name} - Validation\", leave=False)\n",
        "        with torch.no_grad():\n",
        "            for images, masks in val_bar:\n",
        "                images = images.to(device)\n",
        "                masks = masks.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "\n",
        "                dice_loss = dice_loss_fn(torch.sigmoid(outputs), masks)\n",
        "                bce_loss = bce_loss_fn(outputs, masks)\n",
        "                loss = dice_loss + bce_loss\n",
        "\n",
        "                running_val_loss += loss.item()\n",
        "                val_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_val_loss = running_val_loss / len(val_loader)\n",
        "        history[model_name][\"val_loss\"].append(avg_val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Save model weights\n",
        "    save_dir = f\"{folder_path}/trained_models\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    model_path = os.path.join(save_dir, f\"{model_name}.pth\")\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    del model\n",
        "    del optimizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    # Save training history\n",
        "    history_path = os.path.join(save_dir, f\"{model_name}_loss.json\")\n",
        "    with open(history_path, \"w\") as f:\n",
        "        json.dump(history[model_name], f)\n",
        "\n",
        "    print(f\"Saved model and history: {model_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B_6rFR0Oq3yK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_6rFR0Oq3yK",
        "outputId": "43c7ddd9-784f-4922-e029-7aede8b5a499"
      },
      "outputs": [],
      "source": [
        "# Device setup\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# Set model configuration\n",
        "in_channels = 3\n",
        "classes = 1\n",
        "models_dir = f\"{folder_path}/trained_models\"\n",
        "results = {}\n",
        "\n",
        "# Loop through all saved models\n",
        "for filename in os.listdir(models_dir):\n",
        "    if filename.endswith(\".pth\") and filename.startswith('pspnet'):\n",
        "        model_name = filename.replace(\".pth\", \"\")\n",
        "        print(f\"Evaluating model: {model_name}\")\n",
        "\n",
        "        # Parse model architecture and encoder name\n",
        "        arch, encoder = model_name.split(\"_\", 1)\n",
        "        arch_class = smp.PSPNet\n",
        "\n",
        "        # Load model\n",
        "        model = arch_class(\n",
        "            encoder_name=encoder,\n",
        "            encoder_weights=None,\n",
        "            in_channels=in_channels,\n",
        "            classes=classes,\n",
        "            activation=None\n",
        "        ).to(device)\n",
        "        model.load_state_dict(torch.load(os.path.join(models_dir, filename), map_location=device))\n",
        "        model.eval()\n",
        "\n",
        "        # Initialize storage for all predictions and ground truths\n",
        "        y_true, y_pred = [], []\n",
        "\n",
        "        # Run evaluation on the test set\n",
        "        with torch.no_grad():\n",
        "            test_bar = tqdm(test_loader, desc=f\"{model_name} - Testing\", leave=False)\n",
        "            for images, masks in test_bar:\n",
        "                images = images.to(device)\n",
        "                masks = masks.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                probs = torch.sigmoid(outputs)\n",
        "                preds = (probs > 0.5).float()\n",
        "\n",
        "                y_true.extend(masks.cpu().numpy().reshape(-1))\n",
        "                y_pred.extend(preds.cpu().numpy().reshape(-1))\n",
        "\n",
        "        # Compute metrics\n",
        "        metrics = {\n",
        "            \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "            \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
        "            \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
        "            \"Dice Coefficient\": f1_score(y_true, y_pred, zero_division=0),\n",
        "            \"IoU\": jaccard_score(y_true, y_pred, zero_division=0)\n",
        "        }\n",
        "        results[model_name] = metrics\n",
        "\n",
        "        # Save metrics to a JSON file\n",
        "        metrics_path = os.path.join(models_dir, f\"{model_name}_metrics.json\")\n",
        "        with open(metrics_path, \"w\") as f:\n",
        "          json.dump(metrics, f, indent=4)\n",
        "\n",
        "# Print all metrics\n",
        "for name, metrics in results.items():\n",
        "    print(f\"Metrics for {name}:\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cd6b0c5",
      "metadata": {},
      "source": [
        "### Performance evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j_FnIo3A95Fv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_FnIo3A95Fv",
        "outputId": "603a7180-8bad-4c95-dace-f2ce81c398d7"
      },
      "outputs": [],
      "source": [
        "# Model performance evaluation\n",
        "\n",
        "# Path to the directory containing the metric JSON files\n",
        "json_dir = f\"{folder_path}/trained_models/evaluation\"\n",
        "\n",
        "# Collect all JSON files ending with \"_metrics.json\"\n",
        "json_files = [f for f in os.listdir(json_dir) if f.endswith(\"_metrics.json\")]\n",
        "\n",
        "# Container for parsed data\n",
        "rows = []\n",
        "\n",
        "# Loop through each file and extract the relevant info\n",
        "for filename in json_files:\n",
        "    filepath = os.path.join(json_dir, filename)\n",
        "\n",
        "    with open(filepath, 'r') as f:\n",
        "        metrics = json.load(f)\n",
        "\n",
        "    # Parse architecture and backbone from filename\n",
        "    name_parts = filename.replace(\"_metrics.json\", \"\").split(\"_\")\n",
        "    architecture = name_parts[0].upper()\n",
        "    backbone = \"_\".join(name_parts[1:]).title()\n",
        "\n",
        "    # Extract evaluation metrics\n",
        "    metric_items = list(metrics.items())\n",
        "\n",
        "    row = {\n",
        "        \"Architecture\": architecture,\n",
        "        \"Backbone\": backbone\n",
        "    }\n",
        "    row.update(metric_items)\n",
        "    rows.append(row)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# Convert metric values to percentage format (2 decimal places)\n",
        "metric_columns = [col for col in df.columns if col not in [\"Architecture\", \"Backbone\"]]\n",
        "df[metric_columns] = df[metric_columns].applymap(lambda x: f\"{x * 100:.2f}%\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "# Save or display the table\n",
        "print(df.to_string(index=False))  # Show in console  # Show in console"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DPaorou2i1mz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "DPaorou2i1mz",
        "outputId": "03d67523-4550-4cce-9b98-03a52628a1bb"
      },
      "outputs": [],
      "source": [
        "# Show example predictions and compare with the ground truth mask\n",
        "\n",
        "# Load a sample image and mask\n",
        "image_path = f\"{folder_path}/datasets/test/images/tile_107630.png\"\n",
        "mask_path = f\"{folder_path}/datasets/test/masks/mask_107630.png\"\n",
        "model_path = f\"{folder_path}/trained_models/models/unet_efficientnet-b5.pth\"\n",
        "\n",
        "# Load model: U-Net with EfficientNet-B5 backbone as the best-performing model\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"efficientnet-b5\",\n",
        "    encoder_weights='imagenet',\n",
        "    in_channels=3,\n",
        "    classes=1,\n",
        "    activation=None\n",
        ")\n",
        "model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
        "model.eval()\n",
        "\n",
        "# Preprocessing\n",
        "test_transform = A.Compose([\n",
        "    A.Resize(512, 512),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Load and prepare input image\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "image_np = np.array(image)\n",
        "transformed = test_transform(image=image_np)\n",
        "input_tensor = transformed['image'].unsqueeze(0)\n",
        "\n",
        "# Load and resize mask (for comparison only, not normalized)\n",
        "mask = Image.open(mask_path).convert(\"L\").resize((512, 512))\n",
        "mask_np = np.array(mask)\n",
        "\n",
        "# Predict\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)[0, 0]\n",
        "    pred_mask = (torch.sigmoid(output) > 0.5).float().numpy()\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(mask_np, cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(pred_mask, cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ap4wyps7KQM5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ap4wyps7KQM5",
        "outputId": "78ec8811-295b-4a69-9088-7be74f55c740"
      },
      "outputs": [],
      "source": [
        "# Plot train and validation losses by epoch for U-Net, FCN and PSPNet\n",
        "\n",
        "# Paths to the JSON files with losses\n",
        "loss_files = {\n",
        "    \"U-Net + EfficientNet-B5\": f\"{folder_path}/trained_models/train-val loss/unet_efficientnet-b5_loss.json\",\n",
        "    \"FPN + EfficientNet-B5\": f\"{folder_path}/trained_models/train-val loss/fpn_efficientnet-b5_loss.json\",\n",
        "    \"PSPNet + EfficientNet-B5\": f\"{folder_path}/trained_models/train-val loss/pspnet_efficientnet-b5_loss.json\"\n",
        "}\n",
        "\n",
        "# Load and plot each model\n",
        "for model_name, filepath in loss_files.items():\n",
        "    with open(filepath, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    epochs = list(range(1, len(data[\"train_loss\"]) + 1))\n",
        "    train_loss = data[\"train_loss\"]\n",
        "    val_loss = data[\"val_loss\"]\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(epochs, train_loss, label='Train', marker='o', color='royalblue')\n",
        "    plt.plot(epochs, val_loss, label='Val', marker='o', color='firebrick')\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.xticks(epochs)  \n",
        "    plt.legend(loc='upper right', frameon=True)\n",
        "    plt.grid(False)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VCCEBFaGla56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCCEBFaGla56",
        "outputId": "24a4e0d4-396c-418d-b5b2-9a27f30ca35f"
      },
      "outputs": [],
      "source": [
        "# Predict a total area covered by solar panels in Brandenburg\n",
        "\n",
        "# Device selection\n",
        "device = torch.device(\"cuda\" )\n",
        "\n",
        "# Paths\n",
        "image_path = f\"{folder_path}/filtered_images\"\n",
        "model_path = f\"{folder_path}/trained_models/models/unet_efficientnet-b5.pth\" \n",
        "\n",
        "# === Load model ===\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"efficientnet-b5\",\n",
        "    encoder_weights='imagenet',\n",
        "    in_channels=3,\n",
        "    classes=1,\n",
        "    activation=None\n",
        ").to(device)\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# === Transform\n",
        "transform = A.Compose([\n",
        "    A.Resize(512, 512),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# === Area counter\n",
        "total_area_m2 = 0\n",
        "\n",
        "# === Inference over all images\n",
        "image_files = [f for f in os.listdir(image_path)]\n",
        "\n",
        "for filename in tqdm(image_files, desc=\"Predicting\"):\n",
        "    img_path = os.path.join(image_path, filename)\n",
        "\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "    image_np = np.array(image)\n",
        "    transformed = transform(image=image_np)\n",
        "    input_tensor = transformed[\"image\"].unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)[0, 0]\n",
        "        pred_mask = (torch.sigmoid(output).cpu() > 0.5).float().numpy()\n",
        "\n",
        "    total_area_m2 += np.sum(pred_mask)  # 1 pixel = 1 m²\n",
        "\n",
        "# === Print total area\n",
        "print(f\"Total solar panel area detected in Brandenburg:\")\n",
        "print(f\"{int(total_area_m2)} m²\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h_Xkx6MunkGS",
      "metadata": {
        "id": "h_Xkx6MunkGS"
      },
      "source": [
        "### Solar energy generation capacity estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ROcxJWsaA7GX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "ROcxJWsaA7GX",
        "outputId": "e5fd86ec-f082-43ff-ab5c-e8102e15cb50"
      },
      "outputs": [],
      "source": [
        "# Input\n",
        "total_area_m2 = 57325941\n",
        "average_generation_capacity = 0.2  # kW/m²\n",
        "dc_ac_ratio = 1.1\n",
        "system_capacity_kw = (total_area_m2 * average_generation_capacity) / 1000\n",
        "\n",
        "# Load EPW data via pvlib\n",
        "epw_path = f\"{folder_path}/tmy_52.413_13.383_2005_2023.epw\"\n",
        "data, meta = pvlib.iotools.read_epw(epw_path)\n",
        "\n",
        "weather_data = {\n",
        "    'year': data['year'].to_numpy(dtype=float),\n",
        "    'month': data['month'].to_numpy(dtype=float),\n",
        "    'day': data['day'].to_numpy(dtype=float),\n",
        "    'hour': (data['hour']).to_numpy(dtype=float),\n",
        "    'minute': data['minute'].to_numpy(dtype=float),\n",
        "\n",
        "    'dn': data['dni'].to_numpy(dtype=float),\n",
        "    'df': data['dhi'].to_numpy(dtype=float),\n",
        "    'gh': data['ghi'].to_numpy(dtype=float),\n",
        "    'drybulb': data['temp_air'].to_numpy(dtype=float),\n",
        "    'wspd': data['wind_speed'].to_numpy(dtype=float),\n",
        "\n",
        "    'tz': float(meta['TZ']),\n",
        "    'lat': float(meta['latitude']),\n",
        "    'lon': float(meta['longitude']),\n",
        "    'elev': float(meta['altitude'])\n",
        "}\n",
        "\n",
        "# === Run PVWatts with in-memory weather ===\n",
        "pv = pvwatts.default(\"PVWattsSingleOwner\")\n",
        "pv.SolarResource.solar_resource_data = weather_data\n",
        "\n",
        "pv.SystemDesign.system_capacity = system_capacity_kw\n",
        "pv.SystemDesign.dc_ac_ratio = dc_ac_ratio\n",
        "pv.SystemDesign.module_type = 0\n",
        "pv.SystemDesign.array_type = 1\n",
        "pv.SystemDesign.tilt = 30\n",
        "pv.SystemDesign.azimuth = 180\n",
        "\n",
        "pv.execute()\n",
        "\n",
        "# Output\n",
        "annual_kwh = pv.Outputs.ac_annual\n",
        "annual_mwh = annual_kwh / 1000\n",
        "\n",
        "print(f\"Estimated annual energy generation:\")\n",
        "print(f\"{annual_kwh:,.0f} kWh / {annual_mwh:,.2f} MWh\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "994ef0bc",
      "metadata": {},
      "source": [
        "Original solar panel area from the dataset: 9.81 TWh/year\n",
        "\n",
        "Identified solar panel area: 10.72 TWh/year"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecc20211",
      "metadata": {},
      "source": [
        "### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4cdbd6d",
      "metadata": {},
      "source": [
        "This project investigated the application of modern deep learning networks to identify accurate locations and shapes of solar panels in satellite imagery of Brandenburg, Germany. A comprehensive framework is proposed to select a best-performing model for semantic segmentation of solar panels based on WMS satellite imagery and to estimate the solar energy generation of detected installations. \n",
        "\n",
        "The study presented a comparative evaluation of the performance of three fully convolutional network architectures (U-Net, FPN and PSPNet) with three different encoder backbones (EfficientNet-B5, ResNet-50, MiT-B3). Furthermore, data augmentation techniques were applied along with assigning class-specific weights to the loss function to address data imbalance. Almost all the evaluated model configurations demonstrated robust segmentation performance. U-Net with EfficientNet-B5 backbone showed the best prediction results with 85.39% IoU and 92.12% Dice, which is one of the highest scores achieved on a low- resolution satellite imagery in the literature. The model also satisfied the imposed computational constraints, rapidly reaching convergence after the first few training epochs. Reliability of a data source and accuracy of ground truth annotations proved to be the most critical factors affecting the model performance. The method for solar energy output estimation provided a practical means of generating further insights from the identified PV module objects. The results of the project contribute to the application of deep learning models to support data monitoring and validation in solar energy industry and other fields where remote sensing might be needed."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
